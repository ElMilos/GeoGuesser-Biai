model = Sequential()

# Warstwy LSTM równoważne warstwom Conv2D
model.add(Reshape((256, 768), input_shape=(256, 256, 3)))
model.add(LSTM(128, return_sequences=True, activation='tanh'))
model.add(BatchNormalization())
model.add(Dropout(0.4))

model.add(LSTM(64, return_sequences=True, activation='tanh'))
model.add(BatchNormalization())
model.add(Dropout(0.4))

model.add(LSTM(32, return_sequences=False, activation='tanh'))
model.add(BatchNormalization())
model.add(Dropout(0.4))

# Gęste warstwy równoważne Dense w modelu CNN
model.add(Dense(512, activation='relu', kernel_regularizer=regularizers.L2(0.001)))
model.add(Dropout(0.4))
model.add(Dense(256, activation='relu', kernel_regularizer=regularizers.L2(0.001)))
model.add(Dropout(0.4))

# Warstwa wyjściowa
model.add(Dense(num_classes, activation='softmax'))

# Kompilacja modelu
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

model.summary()